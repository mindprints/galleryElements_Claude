{
  "version": 2,
  "uid": "anthropic",
  "front": {
    "title": "Anthropic",
    "chronology": {
      "epochStart": 2021,
      "epochEnd": null,
      "epochEvents": [
        {
          "year": 2021,
          "name": "Company Founded"
        },
        {
          "year": 2022,
          "name": "Constitutional AI Research"
        },
        {
          "year": 2023,
          "name": "Claude 1 Public Release"
        },
        {
          "year": 2023,
          "name": "Claude 2 Launch"
        },
        {
          "year": 2024,
          "name": "Claude 3 Family Release"
        },
        {
          "year": 2025,
          "name": "Claude 3.7 Sonnet Release"
        }
      ]
    }
  },
  "back": {
    "layout": "auto",
    "text": "Anthropic, founded in 2021 by former OpenAI researchers, has established itself as a leading AI safety company focused on developing reliable, interpretable, and steerable AI systems. The company's research-driven approach emphasizes developing systems that are helpful, harmless, and honest through techniques like constitutional AI and RLHF (Reinforcement Learning from Human Feedback).\n\nAnthropic's model portfolio is centered around the Claude family of assistant models. Key offerings include:\n\n• Claude 3 Haiku: Lightweight, high-speed model optimized for efficiency\n• Claude 3 Sonnet: Balanced model offering strong capabilities with reasonable computational requirements\n• Claude 3 Opus: The most capable Claude model with advanced reasoning and knowledge\n• Claude 3.5 Sonnet: Enhanced model with significant improvements in reasoning and factuality\n\nAnthropic's approach to AI development is distinguished by its emphasis on safety research, transparency about model limitations, and focus on reducing harmful outputs while maintaining usefulness. The company has pioneered techniques for aligning AI systems with human values and expectations, including constitutional AI methods that use the model itself to improve alignment. Anthropic's long-term vision centers on building increasingly capable AI systems while ensuring they remain beneficial, controllable, and aligned with human interests even as their capabilities advance."
  },
  "meta": {
    "modified": "2026-02-06T09:23:32.706Z",
    "migratedFrom": "json",
    "categories": [
      "Competitors"
    ]
  }
}