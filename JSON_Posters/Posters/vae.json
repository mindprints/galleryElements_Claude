{
  "version": 2,
  "uid": "vae",
  "front": {
    "title": "VAE",
    "chronology": {
      "epochStart": 2013,
      "epochEnd": 2020,
      "epochEvents": [
        {
          "year": 2013,
          "name": "Original VAE Paper"
        },
        {
          "year": 2015,
          "name": "Conditional VAEs"
        },
        {
          "year": 2016,
          "name": "Importance-Weighted VAEs"
        },
        {
          "year": 2017,
          "name": "β-VAE for Disentanglement"
        },
        {
          "year": 2017,
          "name": "VQ-VAE (Vector Quantized)"
        }
      ]
    }
  },
  "back": {
    "layout": "auto",
    "text": "Variational Autoencoders (VAEs), introduced by Kingma and Welling in 2013, represent a powerful class of generative models that combine elements of deep learning with probabilistic reasoning. Unlike traditional autoencoders that encode inputs deterministically, VAEs map inputs to probability distributions in the latent space, explicitly modeling the uncertainty in the encoding process. This probabilistic approach enables not only data reconstruction but also generation of new samples from the learned distribution.\n\nThe key innovation of VAEs lies in their formulation as a probabilistic graphical model with an inference network (encoder) and a generative network (decoder), trained jointly using variational inference. The encoder outputs parameters of a probability distribution (typically Gaussian) rather than fixed values, and samples from this distribution serve as the latent representation. A carefully designed loss function combines reconstruction error with the Kullback-Leibler divergence between the encoded distribution and a prior, ensuring a well-behaved, continuous latent space. This regularized latent space allows for meaningful interpolation between data points and structured generation of new samples. VAEs have found applications in image generation, text generation, anomaly detection, and representation learning, and have inspired numerous variants including conditional VAEs, VQ-VAEs, and β-VAEs for disentangled representation learning."
  },
  "meta": {
    "modified": "2026-02-08T21:22:07.528Z",
    "categories": [
      "LLMmodels"
    ],
    "created": "2026-02-08T17:56:24.626Z"
  },
  "type": "poster-v2"
}